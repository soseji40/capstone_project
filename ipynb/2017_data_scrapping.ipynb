{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017 Team List\n",
    "team_list = [ 'ARI', 'ATL', 'BAL', 'BOS', 'CHC', 'CHW', 'CIN',\n",
    "       'CLE', 'COL', 'DET', 'HOU', 'KCR', 'LAA', 'LAD', 'MIA',\n",
    "       'MIL', 'MIN', 'NYM', 'NYY', 'OAK', 'PHI', 'PIT', 'SDP',\n",
    "       'SEA', 'SFG', 'STL', 'TBR', 'TEX', 'TOR', 'WSN']\n",
    "\n",
    "#Create a dataframe that mirrors existing data. \n",
    "team_df = pd.DataFrame(columns=['date', 'box', 'team', 'at', 'opponent', 'w_or_l', 'runs', 'runs_allowed',\n",
    "                                    'innings', 'record', 'div_rank', 'gb', 'winning_pitcher', 'losing_pitcher',\n",
    "                                    'save', 'time', 'd_or_n', 'attendance', 'streak', 'double_header', 'runs_pg',\n",
    "                                    'runs_ma', 'runs_allowed_ma', 'opening_day'])\n",
    "    \n",
    "\n",
    "#Use BeautifulSoup to get the data from baseball-reference.com and store them in data frame.     \n",
    "for team in team_list:\n",
    "    df = pd.DataFrame(columns=['date', 'box', 'team', 'at', 'opponent', 'w_or_l', 'runs', 'runs_allowed',\n",
    "                                   'innings', 'record', 'div_rank', 'gb', 'winning_pitcher', 'losing_pitcher',\n",
    "                                   'save', 'time', 'd_or_n', 'attendance', 'streak'])\n",
    "    html = urlopen('https://www.baseball-reference.com/teams/'+team+'/2017-schedule-scores.shtml')\n",
    "\n",
    "    bs = BeautifulSoup(html)\n",
    "    for game in bs.find('table', class_='sortable').findAll('tr'):\n",
    "        results = []\n",
    "        for element in game.find_all('td'):\n",
    "            results.append(element.text)\n",
    "        if len(results) == 19:\n",
    "            df.loc[len(df)] = results\n",
    "            \n",
    "    # adjust date and convert to datetime\n",
    "    df.date = df.date.str.replace(r\"\\(.*\\)\",\"\")\n",
    "    date = []\n",
    "    for i in df.date:\n",
    "        split = i.split(', ')\n",
    "        date.append(split[1] + ', ' + '2017')\n",
    "    df.date = date\n",
    "                \n",
    "    # rolling means for runs and runs allowed\n",
    "    df['runs_pg'] = [0 if x == min(df.date) else df[df.date < x].runs.astype(int).mean() for x in df.date]\n",
    "    df['runs_ma'] = df.runs.rolling(5).mean().shift()\n",
    "    df['runs_allowed_ma'] = df.runs_allowed.rolling(5).mean().shift()\n",
    "    df.runs_allowed_ma.fillna(df.iloc[5].runs_allowed_ma, inplace=True)\n",
    "    \n",
    "    # shift record, div_rank, gb, streak and fill in the first value\n",
    "    df.record = df.record.shift()\n",
    "    df.record.fillna('0-0', inplace=True)\n",
    "    \n",
    "    for col in ['div_rank', 'gb', 'streak']:\n",
    "        df[col] = df[col].shift()\n",
    "        df[col].fillna('0', inplace=True)\n",
    "        \n",
    "    # add double header dummy variable           \n",
    "    df['double_header'] = [1 if ')' in x else 0 for x in df.date]\n",
    "    \n",
    "    # filter down to only home games\n",
    "    df = df[~df['at'].str.contains('@')].reset_index(drop=True)\n",
    "    \n",
    "    # opening day dummy variable\n",
    "    df['opening_day'] = [1 if x == min(df.date) else 0 for x in df.date]\n",
    "    # create one major df\n",
    "    team_df = pd.concat([team_df, df]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df.to_csv('test_data.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:3295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:3554: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:2773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:120: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('test_data.csv')\n",
    "\n",
    "#drop the unneeded columns\n",
    "data.drop(['at', 'winning_pitcher', 'losing_pitcher','save', 'box'],axis=1,inplace=True)\n",
    "\n",
    "#Filling NaNs in the double_header games by using different data set. \n",
    "nan_dh_df = data[(data[\"attendance\"].isnull()) & (data[\"double_header\"] == 1)].sort_values('date')\n",
    "\n",
    "#most double header games only included attendance in the first game\n",
    "for x in list(nan_dh_df.index):\n",
    "    data['attendance'][x] = data.iloc[x + 1]['attendance']\n",
    "\n",
    "#check with retrosheet data why non-double header game attendance is missing\n",
    "data_2015 = pd.read_csv('Data/GL2015.TXT',header=None )\n",
    "\n",
    "#both missing 2015 values are missing in other datasets, must be a collection issue. We will drop thoese rows (4)\n",
    "no_nan_att_data = data[data['attendance'].notnull()]\n",
    "\n",
    "#inings that show NaN is the full 9 inings or 9 inings with no home team batting, fill NaN with 9.0\n",
    "no_nan_att_data['innings'].fillna(9.0,inplace=True)\n",
    "\n",
    "#There's one NaN value in streak feature, it's a opening game. Therefore, we fill it with 0\n",
    "no_nan_att_data[no_nan_att_data['streak'].isnull()]\n",
    "no_nan_att_data['streak'].fillna(0,inplace=True)\n",
    "\n",
    "#Win or Lose has more than w, lose or tie. Agrregate them to win, lose, tied. \n",
    "no_nan_att_data[\"w_or_l\"].replace(to_replace = ['W-wo','W &V;','W &X;', 'W &H;'], value = ['W','W','W','W'], inplace= True)\n",
    "no_nan_att_data[\"w_or_l\"].replace(to_replace = ['L &H;','L &V;'], value =['L','L'], inplace=True)\n",
    "\n",
    "#Record is win-lose foramt, convert it to winning%\n",
    "test_rec = no_nan_att_data.record.values\n",
    "temp_rec_list = []\n",
    "for x in test_rec:\n",
    "    temp_rec_list.append( x.split(\"-\"))\n",
    "\n",
    "w_percent = []\n",
    "for x, y in temp_rec_list:\n",
    "    if (int(x) + int (y)) != 0:\n",
    "        w_percent.append(int(x)/(int(x) + int (y)))\n",
    "    if (int(x) + int (y)) == 0:\n",
    "        w_percent.append(0)\n",
    "\n",
    "no_nan_att_data.record = w_percent\n",
    "\n",
    "#games back has up + int for leading teams and postive int for trailing teams. Make negative value for trailing team.\n",
    "\n",
    "new_gb_t = []\n",
    "for x in no_nan_att_data['gb']:\n",
    "    if 'up' in x:\n",
    "        new_gb_t.append(x.replace('up',''))\n",
    "    if 'up' not in x and 'Tied' not in x:\n",
    "        new_gb_t.append('-' + x )  \n",
    "    if 'Tied' in x:\n",
    "        new_gb_t.append('0')\n",
    "\n",
    "#negative sign and the space like '- 4.0' has to be changed to '-4.0' and some 0s have negative sign \n",
    "\n",
    "new_gb_str=[]\n",
    "for x in new_gb_t:\n",
    "    if x == '-0':\n",
    "        new_gb_str.append(0)        \n",
    "    elif '- ' in x:\n",
    "        new_gb_str.append(x.replace('- ','-'))\n",
    "    else:\n",
    "        new_gb_str.append(x)\n",
    "\n",
    "#set everything to float\n",
    "gb_float_list = []\n",
    "for x in new_gb_str:\n",
    "    gb_float_list.append(float(x))\n",
    "\n",
    "no_nan_att_data['gb']=gb_float_list\n",
    "\n",
    "#timestamp both date and time\n",
    "no_nan_att_data['date'] = pd.to_datetime(no_nan_att_data.date)\n",
    "no_nan_att_data['time'] = pd.to_datetime(no_nan_att_data.time)\n",
    "\n",
    "#convert time to minutes format\n",
    "minutes_list=[]\n",
    "for x in no_nan_att_data['time']:\n",
    "    minutes_list.append(x.hour * 60 + x.minute)\n",
    "no_nan_att_data['time']=minutes_list\n",
    "\n",
    "#year dummies\n",
    "year_dummy = pd.get_dummies(no_nan_att_data['date'].dt.year)\n",
    "year_dummy.columns = list(set(no_nan_att_data['date'].dt.year))\n",
    "for x in range(1990,2017):\n",
    "    year_dummy[x] = [0 for x in range(len(year_dummy.index))]\n",
    "\n",
    "#month dummies\n",
    "month_dummy = pd.get_dummies(no_nan_att_data['date'].dt.month)\n",
    "month_dummy.columns = ['april', 'may','june','july','aug','sep','oct']\n",
    "\n",
    "#weekday dummies\n",
    "weekday_dummy = pd.get_dummies(no_nan_att_data['date'].dt.weekday)\n",
    "weekday_dummy.columns=['M', 'T', 'W', 'TH', 'F', 'SA', 'S']\n",
    "\n",
    "#day or night game dummies\n",
    "day_dummy = pd.get_dummies(no_nan_att_data['d_or_n'],prefix='time')\n",
    "\n",
    "#convert streak to scalar value\n",
    "streak_value = []\n",
    "for x in list(no_nan_att_data['streak'].values):\n",
    "    if type(x) != int:\n",
    "        if '+' in x:\n",
    "            streak_value.append(len(x))\n",
    "        if '-' in x:\n",
    "            streak_value.append(-len(x)) \n",
    "        if x == 0 or x == '0':\n",
    "            streak_value.append(0)\n",
    "    else:\n",
    "        streak_value.append(0)\n",
    "no_nan_att_data['streak'] = streak_value\n",
    "\n",
    "#win or lose result dummy\n",
    "win_dummy = pd.get_dummies(no_nan_att_data['w_or_l'],prefix='result')\n",
    "\n",
    "#attendace has comma, convert it to int\n",
    "no_nan_att_data['attendance'] =[x.replace(',', '') for x in list(no_nan_att_data['attendance'].values)]\n",
    "no_nan_att_data['attendance']= no_nan_att_data['attendance'].astype(int)\n",
    "\n",
    "#putting data together\n",
    "\n",
    "final_data = pd.concat([no_nan_att_data, win_dummy,year_dummy, month_dummy,weekday_dummy, day_dummy],axis=1)\n",
    "\n",
    "#column name year, month, weekday to create groupby and EDA\n",
    "year_list = no_nan_att_data['date'].dt.year\n",
    "final_data['year'] = year_list \n",
    "month_list = no_nan_att_data['date'].dt.month\n",
    "final_data['month'] = month_list \n",
    "weekday_list = no_nan_att_data['date'].dt.weekday\n",
    "final_data['weekday'] = weekday_list \n",
    "\n",
    "#drop dummied features\n",
    "final_drop = final_data.drop(['w_or_l','d_or_n'],axis=1)\n",
    "\n",
    "num_cols = ['runs', 'runs_allowed', 'innings', 'record',\n",
    "       'div_rank', 'gb', 'time', 'attendance','runs_pg',\n",
    "       'runs_ma', 'runs_allowed_ma','last_attendance','streak']\n",
    "\n",
    "cate_cols = ['double_header','opening_day', 'result_L', 'result_T', 'result_W', 'march',\n",
    "       'april', 'may', 'june', 'july', 'aug', 'sep', 'oct', 'M', 'T', 'W',\n",
    "       'TH', 'F', 'SA', 'S', 'time_D', 'time_N','rival']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_drop.to_pickle('test_data_mlb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
